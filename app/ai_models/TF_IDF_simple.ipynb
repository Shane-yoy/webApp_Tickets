{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import setion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "import re\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# On configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")  # URL du serveur MLflow (ton conteneur Docker)\n",
    "mlflow.set_experiment(\"Analyse_Sentiment\")     # Nom du projet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Charger le fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Charge le fichier CSV contenant les tweets.\"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"Données chargées : {data.shape[0]} lignes, {data.shape[1]} colonnes.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Préparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Prépare les données pour l'analyse en nettoyant les textes et en s'assurant de leur qualité.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Jeu de données contenant les colonnes 'text' et 'label'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Jeu de données nettoyé.\n",
    "    \"\"\"\n",
    "    # Vérifier que les colonnes nécessaires existent\n",
    "    if 'text' not in data.columns or 'label' not in data.columns:\n",
    "        raise ValueError(\"Les colonnes 'text' et 'label' doivent exister dans le dataset.\")\n",
    "    \n",
    "    # Supprimer les lignes avec des valeurs manquantes\n",
    "    data.dropna(subset=['text', 'label'], inplace=True)\n",
    "    \n",
    "    # Convertir les labels en entiers\n",
    "    data['label'] = data['label'].astype(int)\n",
    "    \n",
    "    # Nettoyage de base des textes\n",
    "    def clean_text(text):\n",
    "        text = text.lower()  # Convertir en minuscules\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)  # Supprimer les URLs\n",
    "        text = re.sub(r\"@\\w+\", \"\", text)  # Supprimer les mentions Twitter\n",
    "        text = re.sub(r\"#\\w+\", \"\", text)  # Supprimer les hashtags\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Supprimer les caractères non alphabétiques\n",
    "        text = re.sub(r\"\\s+\", \" \", text)  # Supprimer les espaces multiples\n",
    "        return text.strip()\n",
    "    \n",
    "    # Appliquer le nettoyage à la colonne 'text'\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    \n",
    "    # Optionnel : Supprimer les doublons\n",
    "    data.drop_duplicates(subset=['text'], inplace=True)\n",
    "    \n",
    "    # Afficher le statut des données\n",
    "    print(f\"Données préparées : {data.shape[0]} lignes après nettoyage.\")\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diviser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \"\"\"Divise les données en ensembles d'entraînement et de test.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data['text'], data['label'], test_size=0.2, random_state=10\n",
    "    )\n",
    "    print(f\"Train set : {len(X_train)} exemples, Test set : {len(X_test)} exemples.\")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vectorisation avec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(X_train, X_test):\n",
    "    \"\"\"Convertit les textes en vecteurs TF-IDF.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2), stop_words='english')\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    print(\"Données vectorisées avec TF-IDF.\")\n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Entraîner un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_tfidf, y_train):\n",
    "    \"\"\"Entraîne un modèle de régression logistique et log dans MLflow.\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        model = LogisticRegression(max_iter=100, random_state=32)\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        print(\"Modèle entraîné.\")\n",
    "\n",
    "        # Log des paramètres\n",
    "        mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "        mlflow.log_param(\"max_iter\", 100)\n",
    "        mlflow.log_param(\"random_state\", 32)\n",
    "\n",
    "        # Log du score sur l'entraînement\n",
    "        train_accuracy = model.score(X_train_tfidf, y_train)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Sauvegarde du modèle dans MLflow\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Évaluer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test_tfidf, y_test):\n",
    "    \"\"\"Évalue le modèle sur l'ensemble de test et log dans MLflow.\"\"\"\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(\"Rapport de classification :\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Log de la métrique test dans MLflow\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Workflow principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path):\n",
    "    \"\"\"Pipeline principal pour l'analyse de sentiment.\"\"\"\n",
    "    data = load_data(file_path)\n",
    "    data = preprocess_data(data)\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    X_train_tfidf, X_test_tfidf, vectorizer = vectorize_data(X_train, X_test)\n",
    "    model = train_model(X_train_tfidf, y_train)\n",
    "    evaluate_model(model, X_test_tfidf, y_test)\n",
    "    return model, vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Sauvegarde du modèle et du vectoriseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_model\u001b[39m(model, vectorizer, model_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_ML/model_analyse_tweet_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_ML/vectorizer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sauvegarde le modèle et le vectoriseur avec joblib.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     joblib\u001b[38;5;241m.\u001b[39mdump(model, model_filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "def save_model(model, vectorizer, model_filename='app/ai_models/TF_IDF_models/model_analyse_tweet.joblib', vectorizer_filename='app/ai_models/TF_IDF_models/vectorizer.joblib'):\n",
    "    \"\"\"Sauvegarde le modèle et le vectoriseur avec joblib.\"\"\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    joblib.dump(vectorizer, vectorizer_filename)\n",
    "    print(f\"Modèle sauvegardé sous {model_filename} et vectoriseur sous {vectorizer_filename}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Exécution du notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 1526724 lignes, 2 colonnes.\n",
      "Données préparées : 1452209 lignes après nettoyage.\n",
      "Train set : 1161767 exemples, Test set : 290442 exemples.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"app/ai_models/data_set/french_tweets.csv\"  # Remplacez par le chemin vers votre fichier\n",
    "    model, vectorizer = main(file_path)\n",
    "    save_model(model=model, vectorizer=vectorizer)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_saved_model(model_filename='app/ai_models/TF_IDF_models/model_analyse_tweet.joblib', vectorizer_filename='/home/shaney/Bureau/Analyse_de_Sentiment/webApp_Tickets/app/ai_models/TF_IDF_models/vectorizer.joblib'):\n",
    "    \"\"\"Charge le modèle et le vectoriseur sauvegardés avec joblib.\"\"\"\n",
    "    model = joblib.load(model_filename)\n",
    "    vectorizer = joblib.load(vectorizer_filename)\n",
    "    print(f\"Modèle chargé depuis {model_filename} et vectoriseur chargé depuis {vectorizer_filename}.\")\n",
    "    return model, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(model, vectorizer, new_data):\n",
    "    \"\"\"Effectue des prédictions sur de nouvelles données textuelles.\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle chargé pour l'inférence.\n",
    "        vectorizer: Vectoriseur chargé pour transformer les données.\n",
    "        new_data: Liste de chaînes de texte à analyser.\n",
    "    \n",
    "    Returns:\n",
    "        Liste de prédictions effectuées par le modèle.\n",
    "    \"\"\"\n",
    "    # Transformer les nouvelles données avec le vectoriseur\n",
    "    new_data_tfidf = vectorizer.transform(new_data)\n",
    "    \n",
    "    # Effectuer les prédictions avec le modèle\n",
    "    predictions = model.predict(new_data_tfidf)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé depuis /home/shaney/Bureau/Analyse_de_Sentiment/notebooks/TF_IDF_models/model_analyse_tweet.joblib et vectoriseur chargé depuis /home/shaney/Bureau/Analyse_de_Sentiment/notebooks/TF_IDF_models/vectorizer.joblib.\n",
      "Prédictions pour les nouveaux tweets : [0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = load_saved_model()\n",
    "new_tweets = [\"je te déteste espece de monstre !\",\n",
    "\"t'es vraiment nul\",\n",
    "\"vraiment pas engageant\",\n",
    "\"une perte de temps\",\n",
    "\"décevant\",\n",
    "\n",
    "\"encourageant\"\n",
    "\"moi j'aime bien\",\n",
    "\"je trouve le service tres efficaces\"\n",
    "\"je t'aime\",\n",
    "\"j'aime bien passer du temps avec toi <3\"]\n",
    "predictions = predict_new_data(model, vectorizer, new_tweets)\n",
    "print(\"Prédictions pour les nouveaux tweets :\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ticketSentiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
